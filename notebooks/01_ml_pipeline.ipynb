{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238f37e9",
   "metadata": {},
   "source": [
    "# ML Classification Pipeline\n",
    "\n",
    "This notebook demonstrates a minimal scikit-learn pipeline using the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b63ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Title: Machine Learning Pipeline for Iris Classification\n",
    "\n",
    "# Import necessary libraries and custom modules\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'src' directory to the Python path to import modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from preprocess import load_and_prepare_data, scale_features\n",
    "from models import get_logistic_regression_model, get_knn_model, get_svm_model\n",
    "from evaluation import evaluate_model, plot_confusion_matrix, plot_model_comparison\n",
    "\n",
    "print(\"All modules imported successfully!\")\n",
    "\n",
    "datasets_to_run = ['iris', 'breast_cancer']\n",
    "\n",
    "# Wrap entire pipeline in a loop\n",
    "for dataset in datasets_to_run:\n",
    "    print(f\"======================================================\")\n",
    "    print(f\"  RUNNING PIPELINE FOR: {dataset.upper()}\")\n",
    "    print(f\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fe1bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load and prepare the data\n",
    "X_train, X_test, y_train, y_test = load_and_prepare_data(dataset_name=dataset)\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)\n",
    "\n",
    "print(\"Data loaded and split.\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "print(\"\\nFirst 5 rows of training features:\")\n",
    "print(X_train.head())\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "X_train = engineer_features(X_train)\n",
    "X_test = engineer_features(X_test)\n",
    "\n",
    "# Scale the data (which includes the new features)\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebb651",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# In a new cell after loading the data\n",
    "# Combine X_train and y_train for easier plotting\n",
    "train_df = X_train.copy()\n",
    "train_df['target'] = y_train\n",
    "\n",
    "print(\"--- Exploratory Data Analysis (EDA) ---\")\n",
    "\n",
    "# 1. Get a quick overview\n",
    "print(\"Dataset Info:\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "# 2. Check for class imbalance\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(train_df['target'].value_counts())\n",
    "\n",
    "# 3. Visualize distributions and correlations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pairplot for a few features\n",
    "print(\"\\nGenerating Pairplot...\")\n",
    "sns.pairplot(train_df, hue='target', diag_kind='kde')\n",
    "plt.suptitle(f'Pairplot of Features for {dataset}', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix Heatmap\n",
    "print(\"\\nGenerating Correlation Matrix...\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = train_df.corr(numeric_only=True)\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(f'Correlation Matrix of Features for {dataset}')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- EDA Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0402a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Scale the features\n",
    "X_train_scaled, X_test_scaled = scale_features(X_train, X_test)\n",
    "\n",
    "print(\"Features scaled.\")\n",
    "print(\"\\nFirst 5 rows of scaled training features:\")\n",
    "print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68380d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Initialize the models\n",
    "log_reg = get_logistic_regression_model()\n",
    "knn = get_knn_model(n_neighbors=3) # Using 3 neighbors\n",
    "svm = get_svm_model(C=0.5, kernel='linear') # Using a linear kernel\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"K-Nearest Neighbors\": knn,\n",
    "    \"Support Vector Machine\": svm\n",
    "}\n",
    "\n",
    "print(\"Models initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1deeb43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Train and evaluate each model\n",
    "results = {}\n",
    "model_names = []\n",
    "accuracies = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = evaluate_model(model, X_test_scaled, y_test, name)\n",
    "    \n",
    "    # Store results for comparison\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    model_names.append(name)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9354f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Visualize the results\n",
    "\n",
    "# Create the visualizations directory if it doesn't exist\n",
    "if not os.path.exists('../visualizations'):\n",
    "    os.makedirs('../visualizations')\n",
    "\n",
    "# Plot confusion matrices\n",
    "for name, result in results.items():\n",
    "    y_pred = result['model'].predict(X_test_scaled)\n",
    "    plot_confusion_matrix(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        name, \n",
    "        save_path=f'../visualizations/{name.lower().replace(\" \", \"_\")}_confusion_matrix.png'\n",
    "    )\n",
    "\n",
    "# Plot model comparison\n",
    "plot_model_comparison(\n",
    "    model_names, \n",
    "    accuracies, \n",
    "    save_path='../visualizations/model_accuracy_comparison.png'\n",
    ")\n",
    "\n",
    "print(\"\\nAll plots have been generated and saved to the 'visualizations' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6541099",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Conclusion\n",
    "best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "best_accuracy = results[best_model_name]['accuracy']\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Three classification models were trained and evaluated on the Iris dataset.\")\n",
    "print(f\"The models compared were: {', '.join(model_names)}.\")\n",
    "print(f\"\\nBased on accuracy, the best performing model was the **{best_model_name}**.\")\n",
    "print(f\"It achieved an accuracy of **{best_accuracy:.2%}** on the test set.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134f8e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a 'models' directory if it doesn't exist\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "\n",
    "# Get the best model object from your results\n",
    "best_model_object = results[best_model_name]['model']\n",
    "\n",
    "# Define a filename for the saved model\n",
    "model_filename = f'../models/best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
    "\n",
    "# Save the best model\n",
    "save_model(best_model_object, model_filename)\n",
    "\n",
    "# --- Demonstrate loading it back ---\n",
    "# loaded_model = load_model(model_filename)\n",
    "# You could even test the loaded model to ensure it works:\n",
    "# loaded_model_accuracy = evaluate_model(loaded_model, X_test_scaled, y_test, \"Loaded Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
